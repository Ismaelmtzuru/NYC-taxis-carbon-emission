# **Pipeline**
 
![Pipeline Stack Tecnologico](Pipeline_Stack_Tecnológico.jpg)





# Implementación Stack Tecnológico

En este proyecto, utilizaremos diversas herramientas y tecnologías para llevar a cabo el análisis de datos y el desarrollo de modelos de Machine Learning. Consideraremos la implementación de un sistema de gestión de bases de datos para almacenar de manera eficiente los datos recopilados.

## Lenguaje de Programación
Utilizaremos **Python** como lenguaje principal para realizar tareas de Extract, Transform, y Load (ETL), limpieza de datos, y desarrollo de modelos de Machine Learning. Algunas de las bibliotecas clave incluyen:
- Pandas
- Matplotlib
- Seaborn
- Scikit-Learn </n>

[**Ejemplo**](ejemplo.md)

## Bases de Datos
Para consultas y manejo de bases de datos relacionales, emplearemos el lenguaje **SQL**. Además, utilizaremos **Google BigQuery** para almacenar en la nube los datos recopilados mediante consultas SQL.

## Almacenamiento de Datos
- [**Google Cloud Storage:**](storage.md) Servicio en la nube donde se alojarán los datos accesibles para Google BigQuery.

## Plataformas en la Nube
- [**Google Cloud App Engine:**](app_engine.md) Plataforma en la nube que permite el deployment de aplicaciones web de manera escalable.

## Entorno de Desarrollo Colaborativo
- [**Google Colab:**](google_colab.md) Un entorno de Jupyter Notebook en la nube que facilita el análisis interactivo y colaborativo.

## Desarrollo y Despliegue de Modelos
- [**Google Cloud Vertex AI:**](vertex_ai.md) Servicio que permite la creación y despliegue de modelos de Machine Learning a gran escala.

## Orquestación de Trabajos
- [**Apache Airflow:**](Apache_airflow.md) Herramienta de orquestación para la automatización de flujos de trabajo.

## Biblioteca de Análisis de Datos y Modelado
- [**Pycaret:**](PYCARET.md) Biblioteca de Python diseñada para simplificar el proceso de análisis de datos y modelado de Machine Learning.
